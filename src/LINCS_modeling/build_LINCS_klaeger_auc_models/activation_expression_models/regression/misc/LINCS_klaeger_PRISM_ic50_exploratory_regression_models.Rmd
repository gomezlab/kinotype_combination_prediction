---
title: "PRISM ic50 - klaeger - LINCS regression models"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(tidymodels)
library(tictoc)
library(doParallel)
library(patchwork)
library(ROCR)

knitr::opts_knit$set(root.dir = here())
```


```{r}
#binary hit modelling

build_binary_regression_viability_set = function(num_features, all_data, feature_correlations) {
	this_data_filtered = all_data %>%
		select(starts_with("act_"),
					 any_of(feature_correlations$feature[1:num_features]),
					 depmap_id,
					 ccle_name,
					 ic50,
					 broad_id)
}

get_binary_regression_cv_metrics = function(features, data) {
this_dataset = build_binary_regression_viability_set(feature_cor =  binary_feat_cors,
	                                                 num_features = features,
	                                                 all_data = data)

folds = vfold_cv(this_dataset, v = 10)

this_recipe = recipe(ic50 ~ ., this_dataset) %>%
	update_role(-starts_with("act_"),
							-starts_with("exp_"),
							-starts_with("ic50"),
							new_role = "id variable")

rand_forest_spec <- rand_forest(
	trees = 500
) %>% set_engine("ranger") %>%
	set_mode("regression")

this_wflow <-
  workflow() %>%
  add_model(rand_forest_spec) %>%
  add_recipe(this_recipe)

ctrl <- control_resamples(save_pred = TRUE)

fit <-
  this_wflow %>%
  fit_resamples(folds, control = ctrl)

cv_metrics_regression = collect_metrics(fit)

return(cv_metrics_regression)

}

feature_list = c(500, 1000 , 1500, 2000, 2500, 3000, 3500, 4000)

all_binary_regression_metrics = data.frame()
for (i in 1:length(feature_list)) {
  this_metrics = get_binary_regression_cv_metrics(features = feature_list[i], data = binary_data_filtered) %>%
    mutate(feature_number = feature_list[i])
  all_binary_regression_metrics = bind_rows(all_binary_regression_metrics, this_metrics)
}

write_csv(all_binary_regression_metrics, here('results/klaeger_LINCS_binary_hit_regression_results.csv'))
```

```{r}
#all data feature selection

find_all_data_feature_correlations <- function(row_indexes = NA, all_data) {
	if (is.na(row_indexes)) {
		row_indexes = 1:dim(all_data)[1]
	}
	
	all_cor = cor(
		all_data %>% 
									pull(ic50),
								
		all_data %>% 
									select(starts_with(c('act','exp')))
		) %>%
		as.data.frame() %>%
		pivot_longer(everything(), names_to = "feature",values_to = "cor")
	
	
	all_correlations = all_cor %>% 
		mutate(abs_cor = abs(cor)) %>% 
		arrange(desc(abs_cor)) %>% 
		mutate(rank = 1:n()) %>%
		mutate(feature_type = case_when(
			str_detect(feature, "^act_") ~ "Activation",
			str_detect(feature, "^exp_") ~ "Expression",
			T ~ feature
		))

	return(all_correlations)	
}

#excluding wild ic50 values
all_data_filtered = all_model_data %>% 
	filter(ic50 < 30) %>%
	filter(ic50 > 0.0001) %>% 
	mutate(ic50 = log10(ic50))

all_data_more_filtered = all_model_data %>% 
	filter(ic50 < 10) %>%
	filter(ic50 > 0.001) %>% 
	mutate(ic50 = log10(ic50))

all_data_feat_cors = find_all_data_feature_correlations(all_data = all_data_filtered)
all_filtered_data_feat_cors = find_all_data_feature_correlations(all_data = all_data_more_filtered)


write_csv(all_data_filtered, here('results/all_model_data.csv'))
write_csv(all_data_more_filtered, here('results/all_model_data_filtered.csv'))
write_csv(all_data_feat_cors, here('results/all_data_feature_correlations.csv'))
write_csv(all_filtered_data_feat_cors, here('results/all_filtered_data_feature_correlations.csv'))

```


```{r}
#all data modelling

build_all_data_regression_viability_set = function(num_features, all_data, feature_correlations) {
	this_data_filtered = all_data %>%
		select(any_of(feature_correlations$feature[1:num_features]),
					 depmap_id,
					 ccle_name,
					 ic50,
					 broad_id,
					 ic50)
}

get_all_data_regression_cv_metrics = function(features, data) {
this_dataset = build_all_data_regression_viability_set(feature_cor =  all_data_feat_cors,
	                                                 num_features = features,
	                                                 all_data = data)

folds = vfold_cv(this_dataset, v = 10)

this_recipe = recipe(ic50 ~ ., this_dataset) %>%
	update_role(-starts_with("act_"),
							-starts_with("exp_"),
							-starts_with("ic50"),
							new_role = "id variable")

rand_forest_spec <- rand_forest(
	trees = 500
) %>% set_engine("ranger") %>%
	set_mode("regression")

this_wflow <-
  workflow() %>%
  add_model(rand_forest_spec) %>%
  add_recipe(this_recipe)

ctrl <- control_resamples(save_pred = TRUE)

fit <-
  this_wflow %>%
  fit_resamples(folds, control = ctrl)

cv_metrics_regression = collect_metrics(fit)

return(cv_metrics_regression)

}

feature_list = c(500, 1000 , 1500, 2000, 2500, 3000, 3500, 4000)

all_data_regression_metrics = data.frame()
for (i in 1:length(feature_list)) {
  this_metrics = get_all_data_regression_cv_metrics(features = feature_list[i], data = all_data_filtered) %>%
    mutate(feature_number = feature_list[i])
  all_data_regression_metrics = bind_rows(all_data_regression_metrics, this_metrics)
}

write_csv(all_data_regression_metrics, here('results/klaeger_LINCS_regression_results.csv'))
```

```{r}
#final 500 feature model
all_data_filtered = read_csv(here('results/all_model_data_filtered.csv'))
all_data_feat_cors =  read_csv(here('results/all_filtered_data_feature_correlations.csv'))

build_all_data_regression_viability_set = function(num_features, all_data, feature_correlations) {
	this_data_filtered = all_data %>%
		select(any_of(feature_correlations$feature[1:num_features]),
					 depmap_id,
					 ccle_name,
					 ic50,
					 broad_id,
					 ic50)
}

features = 500
data = all_data_filtered

this_dataset = build_all_data_regression_viability_set(feature_cor =  all_data_feat_cors,
	                                                 num_features = features,
	                                                 all_data = data)

folds = vfold_cv(this_dataset, v = 10)

this_recipe = recipe(ic50 ~ ., this_dataset) %>%
	update_role(-starts_with("act_"),
							-starts_with("exp_"),
							-starts_with("ic50"),
							new_role = "id variable")

rand_forest_spec <- rand_forest(
	trees = 500
) %>% set_engine("ranger") %>%
	set_mode("regression")

this_wflow <-
  workflow() %>%
  add_model(rand_forest_spec) %>%
  add_recipe(this_recipe)

ctrl <- control_resamples(save_pred = TRUE)

fit <-
  this_wflow %>%
  fit_resamples(folds, control = ctrl)

cv_metrics_regression_500_filtered = collect_metrics(fit)

predictions_regression_500_filtered = collect_predictions(fit) %>% 
rename('predicted_ic50' = .pred)

predictions_regression_500_filtered %>% 
	ggplot(aes(x = ic50, y = predicted_ic50)) +
	geom_hex() +
	scale_fill_gradient(low="lightblue1",high="darkblue") +
	geom_smooth() +
	labs(title = paste0('Correlation = ', 
											round(
												cor(predictions_regression_500_filtered$ic50, 
														predictions_regression_500_filtered$predicted_ic50),
												4),
											', R-Squared = ', round(
												cv_metrics_regression_500_filtered$mean[2],
												4),
											', RMSE = ', round(cv_metrics_regression_500_filtered$mean[1],
																				 4)),
			 x = "log10_ic50",
			 y = "predicted log10ic50") +
	geom_abline(intercept = 0, slope = 1, size = 0.5, colour = 'red') 
	# xlim(c(-1.5,1.5)) +
	# ylim(c(-1.5,1.5))

ggsave(here('figures/500_feat_all_filtered_data_regression_model_results.png'))

write_rds(fit, here('results/500_feat_lincs_klaeger_regression_model.rds'))
```

```{r}
#analyze xgboost regression model results 

xgboost_regression_metrics = read_csv(here('results/klaeger_LINCS_xgboost_regression_results.csv'))

xgboost_regression_metrics_processed = xgboost_regression_metrics %>% 
	# mutate(across(c('mtry', 'min_n', 'tree_depth', 'learn_rate', 'loss_reduction', 'sample_size'), ~as.factor(.))) %>% 
	drop_na()

parameter_list = c(mtry, min_n, tree_depth, learn_rate, loss_reduction, sample_size)
parameter_name_list = c('mtry', 'min_n', 'tree_depth', 'learn_rate', 'loss_reduction', 'sample_size')

	
xgboost_regression_metrics_processed %>% 
	ggplot() +
	geom_point(aes(x = mtry, y = mean, colour = .metric)) +
	facet_wrap(vars(feature_number))
	
ggsave(here('figures/mtry_xgboost_tuning_results.png'), width = 10, height = 7)


xgboost_regression_metrics_processed %>% 
	ggplot() +
	geom_point(aes(x = min_n, y = mean, colour = .metric)) +
	facet_wrap(vars(feature_number))
	
ggsave(here('figures/min_n_xgboost_tuning_results.png'), width = 10, height = 7)

xgboost_regression_metrics_processed %>% 
	ggplot() +
	geom_point(aes(x = tree_depth, y = mean, colour = .metric)) +
	facet_wrap(vars(feature_number))
	
ggsave(here('figures/tree_depth_xgboost_tuning_results.png'), width = 10, height = 7)

xgboost_regression_metrics_processed %>% 
	ggplot() +
	geom_point(aes(x = learn_rate, y = mean, colour = .metric)) +
	facet_wrap(vars(feature_number))
	
ggsave(here('figures/learn_rate_xgboost_tuning_results.png'), width = 10, height = 7)

xgboost_regression_metrics_processed %>% 
	ggplot() +
	geom_point(aes(x = loss_reduction, y = mean, colour = .metric)) +
	facet_wrap(vars(feature_number))
	
ggsave(here('figures/loss_reduction_xgboost_tuning_results.png'), width = 10, height = 7)

xgboost_regression_metrics_processed %>% 
	ggplot() +
	geom_point(aes(x = sample_size, y = mean, colour = .metric)) +
	facet_wrap(vars(feature_number))
	
ggsave(here('figures/sample_size_xgboost_tuning_results.png'), width = 10, height = 7)

```

